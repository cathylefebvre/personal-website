<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home | Cathy Codes</title>
    <link rel="stylesheet" href="styles.css" />
    <link rel="icon" href="assets/codes_logos/simplified.png" />
  </head>
  <header id="nav-bar" class="nav-bar"></header>
  <script>
    async function loadHeader() {
      const res = await fetch("components/nav-bar.html");
      const html = await res.text();
      document.getElementById("nav-bar").innerHTML = html;
    }
    loadHeader();
    function toggleMenu(x) {
      const nav = document.querySelector(".nav-links");
      x.classList.toggle("change");
      nav.classList.toggle("nav-open");
    }
  </script>

  <body>
    <div class="container">
      <h1>Cathy Lefebvre</h1>
      <section id="about">
        <h2>About Me</h2>
        <p>
          I am a data engineer with a Bachelor of Science in Computer Science
          from the Georgia Institute of Technology and experience building
          scalable, cloud-based data systems using AWS and Python. I have
          designed and optimized data pipelines and backend solutions at
          organizations including Georgia-Pacific, Worthix, and Booz Allen
          Hamilton, where my work focused on event-driven automation,
          configuration-based architecture, and high-performance data
          integration.
        </p>

        <p>
          My technical background includes strong proficiency in AWS (Glue,
          Lambda, Step Functions, S3, EventBridge, DynamoDB, and Redshift),
          Python (pandas, Flask, FastAPI), SQL, and Terraform, along with
          experience using Docker, Git, and other modern development tools. I am
          skilled in developing ETL processes, API integrations, and data
          orchestration frameworks that enable efficient and reliable data flow
          across complex systems.
        </p>
      </section>

      <section id="experience">
        <h2>Experience</h2>

        <h3>Georgia-Pacific</h3>
        <div class="position-line">
          <span class="left">Senior Data Engineer</span>
          <span class="right"><em>Feb 2024 – Sept 2025</em></span>
        </div>
        <!-- <ul>
          <li>
            Developed and maintained various pipelines to enable data movement
            from across the company into the shared enterprise data lake,
            supporting analytics for various teams and departments.
          </li>
          <li>
            Utilized a variety of AWS services including Step Functions, Lambda,
            Glue, DynamoDB, S3, and EventBridge to build configuration-based and
            event-driven pipelines handling diverse data formats and sources.
          </li>
          <li>
            Re-designed pipeline for acquiring data via a multitude of APIs to
            allow better reusability by removing need for individual plugins for
            unique data sources by using a more configuration-driven
            architecture, enhancing efficiency by utilizing asynchronous calls
            and parallel processing.
          </li>
        </ul> -->

        <h3>Worthix</h3>
        <div class="position-line">
          <span class="left">Software Engineer</span>
          <span class="right"><em>Oct 2022 – Jul 2023</em></span>
        </div>
        <!-- <ul>
          <li>
            Worked on the CDC MVPS Portal Team, overseeing the validation,
            processing and distribution of state-level surveillance data to
            relevant public health programs.
          </li>
          <li>
            Enhanced and maintained backend APIs that facilitate seamless data
            flow, ensuring the portal's functionality and accurate data
            presentation while leveraging technologies including Flask, Swagger,
            Pandas, threading, background scheduling, and pyodbc for SQL server
            integration.
          </li>
          <li>
            Updated an existing process for downloading files via SFTP from Perl
            to Python adding notifications if any of the ~75 files a week fails
            to load or the system goes down.
          </li>
        </ul> -->

        <h3>Booz Allen Hamilton (via The Goal)</h3>
        <div class="position-line">
          <span class="left">Python Developer</span>
          <span class="right"><em>Oct 2021 – Oct 2022</em></span>
        </div>

        <h3>InductiveHealth Informatics</h3>
        <div class="position-line">
          <span class="left">Junior Software Developer</span>
          <span class="right"><em>Jan 2021 – Oct 2021</em></span>
        </div>

        <h3>Anthem (via Randstad)</h3>
        <div class="position-line">
          <span class="left">Junior Developer</span>
          <span class="right"><em>Apr 2020 – Dec 2020</em></span>
        </div>

        <h3>Psi Upsilon Fraternity</h3>
        <div class="position-line">
          <span class="left">Director of Chapter Services</span>
          <span class="right"><em>Apr 2019 – Oct 2019</em></span>
        </div>
        <br />
        <div class="position-line">
          <span class="left">Chapter Leadership Consultant</span>
          <span class="right"><em>May 2018 – Apr 2019</em></span>
        </div>
      </section>
      <section id="skills">
        <h2>Skills</h2>
        <p>
          <b>Programming Languages:</b> Python- pandas, Flask, FastAPI, Bash,
          Java, SQL, Perl, C, HTML
        </p>
        <p><b>Tools: </b>Git, BitBucket, JIRA, Terraform</p>
        <p>
          <b>Amazon Web Services:</b> Glue, Lambda, S3, Step Functions,
          EventBridge, Athena, EC2, DynamoDB, Redshift, SNS, SQS
        </p>
      </section>
    </div>
    <footer id="footer"></footer>
    <script>
      async function loadFooter() {
        const res = await fetch("components/footer.html");
        const html = await res.text();
        document.getElementById("footer").innerHTML = html;
      }
      loadFooter();
    </script>
  </body>
</html>
